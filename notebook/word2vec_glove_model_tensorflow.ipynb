{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Introduction to Glove model \n",
    "\n",
    "##### Author - Satyam "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "import mpld3\n",
    "import sys\n",
    "import numpy as np \n",
    "import random\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "np.random.seed(0)\n",
    "sys.path.append(\"../../Utils/\")\n",
    "rcParams['figure.figsize'] = 8, 8\n",
    "mpld3.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from readWikiData import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_co_occur_matrix(sentences, vocab_size, window_size, cc_matrix=None):\n",
    "    X = np.zeros((vocab_size, vocab_size))                    \n",
    "    for sentence in sentences:\n",
    "        n = len(sentence)\n",
    "        for i in xrange(n):\n",
    "            wi = sentence[i] \n",
    "            \n",
    "            start = max(0, i - window_size)\n",
    "            end = min(n, i + window_size)\n",
    "            \n",
    "            if i - window_size < 0:\n",
    "                points = 1.0/(1 + i)\n",
    "                X[wi, 0] += points\n",
    "                X[0, wi] += points\n",
    "            \n",
    "            if i + window_size > n:\n",
    "                points = 1.0/( n - i)\n",
    "                X[wi, 0] += points\n",
    "                X[0, wi] += points\n",
    "                \n",
    "            for j in xrange(start, i):\n",
    "                points = 1.0/(i - j)\n",
    "                wj = sentence[j]\n",
    "                X[wi, wj] += points\n",
    "                X[wj, wi] += points\n",
    "                \n",
    "            for j in xrange(i + 1, end):\n",
    "                points = 1.0/(j - i)\n",
    "                wj = sentence[j]\n",
    "                X[wi, wj] += points\n",
    "                X[wj, wi] += points\n",
    "    #np.save(X, cc_matrix)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Glove model normalize the co-occurence score of each using the following equation :- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$f_{i, j}(X) = \\left( \\frac{X_{i, j}}{X_{max}} \\right)^\\alpha     ,if X_{i, j} < X_{max} $$\n",
    "$$= 1, otherwise $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def getfX(X, xmax, alpha):\n",
    "    fX = np.zeros(X.shape)\n",
    "    fX[X < xmax] = (X[X<xmax]/float(xmax))**alpha\n",
    "    fX[X >= xmax] = 1.0 \n",
    "    return fX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The cost function in the glove model tries to learn a lower dimensional representation of the input coocurrence matrix\n",
    "using the following equation :- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$J = \\sum_{i}\\sum_{j} f\\left(X_{i, j}\\right)\\left(w_{i}^T u_{j} + b_{i} + c_{j} + mu - \\log X_{i, j} \\right)^2 \n",
    "+ \\lambda \\left( {\\lVert W \\rVert }^2 + {\\lVert u \\rVert }^2 + {\\lVert b \\rVert }^2 + {\\lVert c \\rVert }^2 \\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def normalize(X):\n",
    "    return np.log(X + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nkeep_words = set([\\n                'king', 'man', 'woman',\\n                'east', 'eastern', 'west', 'western', 'north', 'northern', 'south', 'southern', \\n                'japan', 'japanese', 'england', 'english', 'australia', 'australian', 'china', 'chinese',                 'italy', 'italian', 'french', 'france', 'spain', 'spanish', 'december', 'november', 'june',\\n                'january', 'february', 'march', 'april', 'may', 'july', 'august', 'september', 'october',\\n            ])\\n\\nsentences, word2idx = get_sentences_with_word2idx_limit_vocab(n_vocab=2000, keep_words=keep_words)\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences, word2idx = get_wikipedia_data(n_files=20, n_vocab=2000, by_paragraph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = build_co_occur_matrix(sentences=sentences, vocab_size=len(word2idx), window_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fX = getfX(X=X, xmax=100, alpha=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "logX = normalize(X=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "V = len(word2idx)\n",
    "embedding_size = 50\n",
    "learning_rate = 10e-5\n",
    "epochs = 10001\n",
    "reg=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W = np.random.randn(V, embedding_size)/np.sqrt(V + embedding_size)\n",
    "b = np.zeros(V)\n",
    "U = np.random.randn(V, embedding_size)/np.sqrt(V + embedding_size)\n",
    "c = np.zeros(V)\n",
    "mu = normalize(X).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tfW = tf.Variable(W.astype(np.float32))\n",
    "tfb = tf.Variable(b.reshape(V, 1).astype(np.float32))\n",
    "tfU = tf.Variable(U.astype(np.float32))\n",
    "tfc = tf.Variable(c.reshape(1, V).astype(np.float32))\n",
    "tfLogX = tf.placeholder(tf.float32, shape=(V, V))\n",
    "tffX = tf.placeholder(tf.float32, shape=(V, V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "delta = tf.matmul(tfW, tf.transpose(tfU)) + tfb + tfc + mu - tfLogX\n",
    "cost = tf.reduce_sum(tffX * delta * delta)\n",
    "for param in (tfW, tfb, tfU, tfc):\n",
    "    cost += reg*tf.reduce_sum(param * param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_op = tf.train.MomentumOptimizer(learning_rate, momentum=0.9).minimize(cost)\n",
    "init = tf.global_variables_initializer()\n",
    "session = tf.InteractiveSession()\n",
    "session.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 cost: 2366837.04804\n",
      "epoch: 1000 cost: 62503.5671601\n",
      "epoch: 2000 cost: 61792.6671071\n",
      "epoch: 3000 cost: 61613.6836228\n"
     ]
    }
   ],
   "source": [
    "costs = []\n",
    "sentence_indexes = range(len(sentences))\n",
    "        \n",
    "for epoch in xrange(epochs):\n",
    "    delta = W.dot(U.T) + b.reshape(V, 1) + c.reshape(1, V) + mu - logX\n",
    "    cost = ( fX * delta * delta ).sum()\n",
    "    costs.append(cost)\n",
    "    if epoch % 1000 == 0:\n",
    "        print \"epoch:\", epoch, \"cost:\", cost\n",
    "\n",
    "    session.run(train_op, feed_dict={tfLogX: logX, tffX: fX})\n",
    "    W, b, U, c = session.run([tfW, tfb, tfU, tfc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.plot(costs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "word2vec = np.mean([W, U], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "idx2word = {v:k for k, v in word2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "model = TSNE()\n",
    "Z = model.fit_transform(word2vec) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(Z[:,0], Z[:,1])\n",
    "plt.title(\"glove word2vec\")\n",
    "rcParams['figure.figsize'] = 12, 12\n",
    "for i in xrange(len(idx2word)):\n",
    "    try:\n",
    "        plt.annotate(s=idx2word[i].encode(\"utf8\"), xy=(Z[i,0], Z[i,1]))\n",
    "    except:\n",
    "        print \"bad string:\", idx2word[i]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def find_analogies(w1, w2, w3, We, word2idx):\n",
    "    king = We[word2idx[w1]]\n",
    "    man = We[word2idx[w2]]\n",
    "    woman = We[word2idx[w3]]\n",
    "    v0 = king - man + woman\n",
    "\n",
    "    def dist1(a, b):\n",
    "        return np.linalg.norm(a - b)\n",
    "    def dist2(a, b):\n",
    "        return 1 - a.dot(b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "    for dist, name in [(dist1, 'Euclidean'), (dist2, 'cosine')]:\n",
    "        min_dist = float('inf')\n",
    "        best_word = ''\n",
    "        for word, idx in word2idx.iteritems():\n",
    "            if word not in (w1, w2, w3):\n",
    "                v1 = We[idx]\n",
    "                d = dist(v0, v1)\n",
    "                if d < min_dist:\n",
    "                    min_dist = d\n",
    "                    best_word = word\n",
    "        print \"closest match by\", name, \"distance:\", best_word\n",
    "        print w1, \"-\", w2, \"=\", best_word, \"-\", w3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "we = word2vec\n",
    "w2i = word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "find_analogies(w1='1', w2='3', w3='2',We=we, word2idx=w2i)\n",
    "find_analogies(w1='england', w2='london', w3='france',We=we, word2idx=w2i)\n",
    "find_analogies(w1='english', w2='french', w3='german',We=we, word2idx=w2i)\n",
    "find_analogies(w1='east', w2='west', w3='north',We=we, word2idx=w2i)\n",
    "find_analogies(w1='lower', w2='higher', w3='low',We=we, word2idx=w2i)\n",
    "find_analogies(w1='two', w2='three', w3='four',We=we, word2idx=w2i)\n",
    "find_analogies(w1='december', w2='november', w3='january',We=we, word2idx=w2i)\n",
    "find_analogies(w1='december', w2='november', w3='july',We=we, word2idx=w2i)\n",
    "find_analogies(w1='two', w2='three', w3='five',We=we, word2idx=w2i)\n",
    "find_analogies(w1='eastern', w2='western', w3='northern',We=we, word2idx=w2i)\n",
    "find_analogies(w1='king', w2='queen', w3='women',We=we, word2idx=w2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "words = ['east', 'eastern', 'west', 'western', 'north', 'northern', 'south', 'southern']\n",
    "\n",
    "idx = [word2idx[w] for w in words]\n",
    "\n",
    "tsne = TSNE()\n",
    "Z = tsne.fit_transform(we)\n",
    "Z = Z[idx]\n",
    "plt.scatter(Z[:,0], Z[:,1])\n",
    "for i in xrange(len(words)):\n",
    "    plt.annotate(s=words[i], xy=(Z[i,0], Z[i,1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "words = ['japan', 'japanese', 'england', 'english', 'australia', 'australian', 'china', \\\n",
    "         'chinese', 'italy', 'italian', 'french', 'france', 'spain', 'spanish']\n",
    "\n",
    "idx = [word2idx[w] for w in words]\n",
    "\n",
    "tsne = TSNE()\n",
    "Z = tsne.fit_transform(we)\n",
    "Z = Z[idx]\n",
    "\n",
    "plt.scatter(Z[:,0], Z[:,1])\n",
    "for i in xrange(len(words)):\n",
    "    plt.annotate(s=words[i], xy=(Z[i,0], Z[i,1]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "words = ['large', 'larger', 'largest', \n",
    "         'great', 'greater', 'greatest', \n",
    "         'high', 'higher', 'highest']\n",
    "\n",
    "idx = [word2idx[w] for w in words]\n",
    "\n",
    "tsne = TSNE()\n",
    "Z = tsne.fit_transform(we)\n",
    "Z = Z[idx]\n",
    "\n",
    "plt.scatter(Z[:,0], Z[:,1])\n",
    "for i in xrange(len(words)):\n",
    "    plt.annotate(s=words[i], xy=(Z[i,0], Z[i,1]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### References - \n",
    "\n",
    "http://www.foldl.me/2014/glove-python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_kernel",
   "language": "python",
   "name": "deep_learning_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
